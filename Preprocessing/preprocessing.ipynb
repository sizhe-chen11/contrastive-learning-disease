{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Utilities')\n",
    "import utils\n",
    "import udfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../Data/raw_data/NTCMRC_all.xlsx\"\n",
    "df = pd.read_excel(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of df as df1\n",
    "df1 = df.copy()\n",
    "\n",
    "# Replace '\\\\N' with NaN\n",
    "df1 = df1.replace('\\\\N', np.nan)\n",
    "\n",
    "# Specify the columns to be converted to FLOAT\n",
    "columns_to_convert1 = ['BMI', 'Triglyceride_y', 'gamgt', 'waist_y', 'mst', 'egfrn', 'Estimated_GFR_x', 'Alb_Cre_ratio', 'HOMA_IR', 'HS_CRP', \\\n",
    "                       'LDL_C_direct', 'LDL_C_HDL_C', 'Adiponectin', 'Leptin', 'Uric_Acid','Insulin', 'ALT_GPT']\n",
    "\n",
    "# Specify the columns to be converted to INT\n",
    "columns_to_convert2 = ['脂肪肝 fatty Liver (0:正常  1:mild 2:moderate 3:severe)', 'smoke', 'smoke_q', \\\n",
    "                       'sex', 'w', 'coffee', 'betel']\n",
    "\n",
    "# Convert the specified columns to float and fill missing/unconvertible values with NaN\n",
    "for column in columns_to_convert1:\n",
    "    df1[column] = pd.to_numeric(df1[column], errors='coerce')\n",
    "\n",
    "# Convert the specified columns to int and fill missing/unconvertible values with NaN\n",
    "for column in columns_to_convert2:\n",
    "    df1[column] = pd.to_numeric(df1[column], errors='coerce').astype(pd.Int64Dtype())\n",
    "\n",
    "# Calculate FLI using the formula and defined as df2\n",
    "df2 = df1.copy()\n",
    "df2['FLI'] = (np.exp(0.953 * np.log(df2['Triglyceride_y']) + 0.139 * df2['BMI'] + 0.718 * np.log(df2['gamgt']) \\\n",
    "     + 0.053 * df2['waist_y'] - 15.745)) / (1 + np.exp(0.953 * np.log(df2['Triglyceride_y']) \\\n",
    "    + 0.139 * df2['BMI'] + 0.718 * np.log(df2['gamgt']) + 0.053 * df2['waist_y'] - 15.745)) * 100\n",
    "\n",
    "# Derive FL_echo based on ultrasound results column\n",
    "df2['FL_echo'] = df2['脂肪肝 fatty Liver (0:正常  1:mild 2:moderate 3:severe)']\n",
    "df2['FL_echo'] = df2['FL_echo'].replace('<NA>', np.nan)\n",
    "df2['fl_status'] = df2.apply(utils.derive_fl_status, axis=1)\n",
    "\n",
    "#Derive homa_ir_check, hs_crp_check, and mst_total to determine MAFLD risk factors\n",
    "df2['homa_ir_check'] = df2['HOMA_IR'].apply(lambda x: 1 if x >= 2.5 else 0)\n",
    "df2['hs_crp_check'] = df2['HS_CRP'].apply(lambda x: 1 if x > 2 else 0)\n",
    "df2['mst_total'] = df2[['w', 'hyper', 'HDL', 'fg', 'trig', 'homa_ir_check', 'hs_crp_check']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive target vars\n",
    "df3 = utils.derive_MAFLD_with_multi_label(utils.derive_MAFLD(df2))\n",
    "df4 = utils.derive_CKD(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_extract = ['HBsAg_x', 'Anti_HCV_x']\n",
    "df5 = df4.copy()\n",
    "for column in columns_to_extract:\n",
    "    new_column_name = column + '_num'\n",
    "    df5[new_column_name] = df5[column].apply(utils.extract_numeric_value)\n",
    "\n",
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survey Data Processing\n",
    "\n",
    "\"\"\" Survey basic information part \"\"\"\n",
    "df6['diet'] = df6['diet'].apply(lambda x: x if x in [1.0, 2.0, 3.0, 4.0] else np.nan) #1:葷 2:全素 3:早素 4:其他\n",
    "df6['job_c'] = df6['job_c'].apply(lambda x: x if x in [1, 0] else np.nan) #0:坐辦公室 1:體力勞動\n",
    "df6['mstatus'] = df6['mstatus'].apply(lambda x: x if x in [1, 2, 3, 4] else np.nan) # 1:未婚 2:已婚 3:離婚或分居 4:鰥寡\n",
    "df6['children'] = df6['children'].apply(lambda x: x if x in [0, 1, 2, 3] else ('above 3' if x in [4, 5, 6, 7, 8] else np.nan))# num of children\n",
    "df6['fam_self'] = df6['fam_self'].apply(lambda x: x if x in [1, 0] else np.nan) # 居住成員 (獨居): 0:沒有 1:有\n",
    "df6['care_self'] = df6['care_self'].apply(lambda x: x if x in [1, 0] else np.nan) # 誰照顧你(自理): 0:沒有 1:有\n",
    "df6['eco_self'] = df6['eco_self'].apply(lambda x: x if x in [1, 0] else np.nan) # 經濟來源 (自己): 0:沒有 1:有\n",
    "df6['insurance'] = df6['insurance'].apply(lambda x: x if x in [1, 0] else np.nan) # 保險狀況: 0:沒有 1:有\n",
    "\n",
    "\"\"\" Survey life style part \"\"\"\n",
    "df6['smoke'] = df6['smoke'].apply(lambda x: x if pd.isna(x) or x in [0, 1] else np.nan) # 您曾經抽過菸嗎？: 0:沒有 1:有\n",
    "df6['smoke_q'] = df6['smoke_q'].apply(lambda x: x if pd.isna(x) or x in [0, 1, 2] else np.nan) # 您是否曾戒過菸？: 0:一直有在抽 1:已戒菸N年(未再抽) 2:戒過N年，現在又抽\n",
    "df6['coffee'] = df6['coffee'].apply(lambda x: x if pd.isna(x) or x in [1, 0] else np.nan) # 您有喝咖啡的習慣嗎？: 0:沒有 1:有\n",
    "df6['betel'] = df6['betel'].apply(lambda x: x if pd.isna(x) or x in [1, 0] else np.nan) # 您曾經嚼過檳榔嗎？: 0:沒有 1:有\n",
    "\n",
    "\"\"\" Survey self genetic part  \"\"\"\n",
    "df6['hypertension'] = df6['hypertension'].apply(lambda x: x if x in [1, 0] else np.nan) # 自己有無高血壓: 0:沒有 1:有\n",
    "df6['Dysrhythmia'] = df6['Dysrhythmia'].apply(lambda x: x if x in [1, 0] else np.nan) # 自己有無心律不整 0:沒有 1:有\n",
    "df6['ap'] = df6['ap'].apply(lambda x: x if x in [1, 0] else np.nan) # 自己有無心絞痛 0:沒有 1:有\n",
    "df6['ami'] = df6['ami'].apply(lambda x: x if x in [1, 0] else np.nan) # 自己有無心肌梗塞 0:沒有 1:有\n",
    "df6['Hyperlipidemia'] = df6['Hyperlipidemia'].apply(lambda x: x if x in [1, 0] else np.nan) # 自己有無高血脂 0:沒有 1:有\n",
    "df6['HF'] = df6['HF'].apply(lambda x: x if x in [1, 0] else np.nan) # 自己有無心臟衰竭 0:沒有 1:有\n",
    "df6['endocrine'] = df6['endocrine'].apply(lambda x: x if x in [1, 0] else np.nan) # 自述有內分泌疾病 0:沒有 1:有\n",
    "df6['Thyroid'] = df6['Thyroid'].apply(lambda x: x if x in [1, 0] else np.nan) # 自己有無甲狀腺疾病 0:沒有 1:有\n",
    "df6['gastritis'] = df6['gastritis'].apply(lambda x: x if x in [1, 0] else np.nan) # 自述有胃炎 0:沒有 1:有\n",
    "df6['hepatitis_o'] = df6['hepatitis_o'].apply(lambda x: x if x in [1, 0] else np.nan) # 自述有其他肝病、肝硬化等疾病 0:沒有 1:有\n",
    "df6['FLD'] = df6['FLD'].apply(lambda x: x if x in [1, 0] else np.nan) # 自己有無脂肪肝 0:沒有 1:有\n",
    "df6['fibrosis'] = df6['fibrosis'].apply(lambda x: x if x in [1, 0] else np.nan) # 自己有無肝纖維化 0:沒有 1:有\n",
    "df6['Cirrhosis'] = df6['Cirrhosis'].apply(lambda x: x if x in [1, 0] else np.nan)# 自己有無肝硬化 0:沒有 1:有\n",
    "df6['Polyposis'] = df6['Polyposis'].apply(lambda x: x if x in [1, 0] else np.nan)# 自己有無大腸瘜肉 0:沒有 1:有\n",
    "df6['ibs'] = df6['ibs'].apply(lambda x: x if x in [1, 0] else np.nan)# 自己有無腸躁症 0:沒有 1:有\n",
    "\n",
    "\"\"\" Survey parents genetic part  \"\"\"\n",
    "df6['fm_cardio'] = df6.apply(udfs.determine_fm_cardio, axis=1)\n",
    "df6['fm_hyper'] = df6.apply(udfs.determine_fm_hyper, axis=1)\n",
    "df6['fm_dys'] = df6.apply(udfs.determine_fm_dys, axis=1)\n",
    "df6['fm_ap'] = df6.apply(udfs.determine_fm_ap, axis=1)\n",
    "df6['fm_ami'] = df6.apply(udfs.determine_fm_ami, axis=1)\n",
    "df6['fm_lipid'] = df6.apply(udfs.determine_fm_lipid, axis=1)\n",
    "df6['fm_hf'] = df6.apply(udfs.determine_fm_hf, axis=1)\n",
    "df6['fm_dm'] = df6.apply(udfs.determine_fm_dm, axis=1)\n",
    "df6['fm_Thyroid'] = df6.apply(udfs.determine_fm_Thyroid, axis=1)\n",
    "\n",
    "\"\"\" Survey brothers and sisters genetic part  \"\"\"\n",
    "df6['bs_cardio'] = df6['bs_cardio'].apply(lambda x: x if x in [1, 0] else np.nan) # 兄弟姊妹有心臟血管疾病: 0:沒有 1:有\n",
    "df6['bs_hyper'] = df6['bs_hyper'].apply(lambda x: x if x in [1, 0] else np.nan) # 兄弟姊妹有無高血壓: 0:沒有 1:有\n",
    "df6['bs_dys'] = df6['bs_dys'].apply(lambda x: x if x in [1, 0] else np.nan) # 兄弟姊妹有無心律不整 0:沒有 1:有\n",
    "df6['bs_ap'] = df6['bs_ap'].apply(lambda x: x if x in [1, 0] else np.nan) # 兄弟姊妹有無心絞痛 0:沒有 1:有\n",
    "df6['bs_ami'] = df6['bs_ami'].apply(lambda x: x if x in [1, 0] else np.nan) # 兄弟姊妹有無心肌梗塞 0:沒有 1:有\n",
    "df6['bs_lipid'] = df6['bs_lipid'].apply(lambda x: x if x in [1, 0] else np.nan) # 兄弟姊妹有無高血脂 0:沒有 1:有\n",
    "df6['bs_hf'] = df6['bs_hf'].apply(lambda x: x if x in [1, 0] else np.nan) # 兄弟姊妹有無心臟衰竭 0:沒有 1:有\n",
    "df6['bs_dm'] = df6['bs_dm'].apply(lambda x: x if x in [1, 0] else np.nan) # 兄弟姊妹有無糖尿病 0:沒有 1:有\n",
    "df6['bs_Thyroid'] = df6['bs_Thyroid'].apply(lambda x: x if x in [1, 0] else np.nan) # 兄弟姊妹有無甲狀腺疾病 0:沒有 1:有\n",
    "\n",
    "\"\"\" Survey children genetic part \"\"\"\n",
    "df6['chi_cardio'] = df6['chi_cardio'].apply(lambda x: x if x in [1, 0] else np.nan) # 子女有心臟血管疾病: 0:沒有 1:有\n",
    "df6['chi_hyper'] = df6['chi_hyper'].apply(lambda x: x if x in [1, 0] else np.nan) # 子女有無高血壓: 0:沒有 1:有\n",
    "df6['chi_dys'] = df6['chi_dys'].apply(lambda x: x if x in [1, 0] else np.nan) # 子女有無心律不整 0:沒有 1:有\n",
    "df6['chi_ap'] = df6['chi_ap'].apply(lambda x: x if x in [1, 0] else np.nan) # 子女有無心絞痛 0:沒有 1:有\n",
    "df6['chi_ami'] = df6['chi_ami'].apply(lambda x: x if x in [1, 0] else np.nan) # 子女有無心肌梗塞 0:沒有 1:有\n",
    "df6['chi_lipid'] = df6['chi_lipid'].apply(lambda x: x if x in [1, 0] else np.nan) # 子女有無高血脂 0:沒有 1:有\n",
    "df6['chi_hf'] = df6['chi_hf'].apply(lambda x: x if x in [1, 0] else np.nan) # 子女有無心臟衰竭 0:沒有 1:有\n",
    "df6['chi_dm'] = df6['chi_dm'].apply(lambda x: x if x in [1, 0] else np.nan) # 子女有無糖尿病 0:沒有 1:有\n",
    "df6['chi_Thyroid'] = df6['chi_Thyroid'].apply(lambda x: x if x in [1, 0] else np.nan) # 子女有無甲狀腺疾病 0:沒有 1:有\n",
    "\n",
    "\"\"\" Survey scoring \"\"\"\n",
    "#RAND36 score\n",
    "df6['RAND36_PF'] = df6['RAND36_PF'].apply(udfs.categorize_rand36_score)\n",
    "df6['RAND36_RP'] = df6['RAND36_RP'].apply(udfs.categorize_rand36_score)\n",
    "df6['RAND36_RE'] = df6['RAND36_RE'].apply(udfs.categorize_rand36_score)\n",
    "df6['RAND36_EF'] = df6['RAND36_EF'].apply(udfs.categorize_rand36_score)\n",
    "df6['RAND36_EWB'] = df6['RAND36_EWB'].apply(udfs.categorize_rand36_score)\n",
    "df6['RAND36_SF'] = df6['RAND36_SF'].apply(udfs.categorize_rand36_score)\n",
    "df6['RAND36_BP'] = df6['RAND36_BP'].apply(udfs.categorize_rand36_score)\n",
    "df6['RAND36_GH'] = df6['RAND36_GH'].apply(udfs.categorize_rand36_score)\n",
    "\n",
    "# Anxiety score\n",
    "df6['Anxiety_Level'] = df6['Anxiety'].apply(udfs.categorize_anxiety_or_depression)\n",
    "df6['Depression_Level'] = df6['Depresscore'].apply(udfs.categorize_anxiety_or_depression)\n",
    "df6['HAD'] = df6['HAD'].apply(udfs.categorize_HAD_total)\n",
    "\n",
    "# PSQI\n",
    "df6['c1_Sleep_Quality'] = df6['c1_Sleep_Quality'].apply(lambda x: x if pd.isna(x) or x in [0, 1, 2, 3] else np.nan)\n",
    "df6['c2_Latency'] = df6['c2_Latency'].apply(lambda x: x if pd.isna(x) or x in [0, 1, 2, 3] else np.nan)\n",
    "df6['c3_Duration'] = df6['c3_Duration'].apply(lambda x: x if pd.isna(x) or x in [0, 1, 2, 3] else np.nan)\n",
    "df6['c4_Efficiency'] = df6['c4_Efficiency'].apply(lambda x: x if pd.isna(x) or x in [0, 1, 2, 3] else np.nan)\n",
    "df6['c5_Disturbance'] = df6['c5_Disturbance'].apply(lambda x: x if pd.isna(x) or x in [0, 1, 2, 3] else np.nan)\n",
    "df6['c6_Use_Medicatin'] = df6['c6_Use_Medicatin'].apply(lambda x: x if pd.isna(x) or x in [0, 1, 2, 3] else np.nan)\n",
    "df6['c7_Daytime_dysfunction'] = df6['c7_Daytime_dysfunction'].apply(lambda x: x if pd.isna(x) or x in [0, 1, 2, 3] else np.nan)\n",
    "\n",
    "df6['MNA'] = df6['MNA'].apply(udfs.categorize_mna)\n",
    "df6['AUDIT'] = df6['AUDIT'].apply(udfs.categorize_AUDIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of survey_features 74\n",
      "Number of remaining features: 23\n",
      "['AUDIT', 'c5_Disturbance', 'c3_Duration', 'c2_Latency', 'c7_Daytime_dysfunction', 'c6_Use_Medicatin', 'c1_Sleep_Quality', 'betel', 'coffee', 'smoke', 'insurance', 'eco_self', 'care_self', 'HF', 'fam_self', 'RAND36_SF', 'RAND36_PF', 'RAND36_EWB', 'RAND36_BP', 'RAND36_EF', 'RAND36_GH', 'RAND36_RP', 'RAND36_RE']\n"
     ]
    }
   ],
   "source": [
    "# Select survey features\n",
    "survey_features = ['diet', 'job_c', 'mstatus', 'children', 'fam_self', 'care_self', 'eco_self', 'insurance', \\\n",
    "    'smoke', 'smoke_q', 'coffee', 'betel',\\\n",
    "    'hypertension', 'Dysrhythmia', 'ap', 'ami', 'Hyperlipidemia', 'HF', 'endocrine', 'Thyroid', \\\n",
    "    'gastritis', 'hepatitis_o', 'FLD', 'fibrosis', 'Cirrhosis', 'Polyposis', 'ibs', \\\n",
    "    'fm_cardio', 'fm_hyper', 'fm_dys', 'fm_ap', 'fm_ami', 'fm_lipid', 'fm_hf', 'fm_dm', 'fm_Thyroid', \\\n",
    "    'bs_cardio', 'bs_hyper', 'bs_dys', 'bs_ap', 'bs_ami', 'bs_lipid', 'bs_hf', 'bs_dm', 'bs_Thyroid',\n",
    "    'chi_cardio', 'chi_hyper', 'chi_dys', 'chi_ap', 'chi_ami', 'chi_lipid', 'chi_hf', 'chi_dm', 'chi_Thyroid', \\\n",
    "    'RAND36_PF', 'RAND36_RP', 'RAND36_RE', 'RAND36_EF', 'RAND36_EWB', 'RAND36_SF', 'RAND36_BP', 'RAND36_GH', \\\n",
    "    'Anxiety_Level', 'Depression_Level', 'HAD', \\\n",
    "    'c1_Sleep_Quality', 'c2_Latency', 'c3_Duration', 'c4_Efficiency', 'c5_Disturbance', 'c6_Use_Medicatin', 'c7_Daytime_dysfunction', \\\n",
    "    'MNA', 'AUDIT']\n",
    "\n",
    "print(\"number of survey_features\",len(survey_features))\n",
    "# Calculate the null ratio for each survey data feature and filter null value higher than 20%\n",
    "df6_survey = df6[survey_features]\n",
    "survey_null_ratios = (df6_survey.isnull().mean() * 100).sort_values(ascending=False)\n",
    "filtered_survey_data = survey_null_ratios[survey_null_ratios <= 20]\n",
    "# filtered_survey_data = survey_null_ratios[survey_null_ratios <= 100]\n",
    "\n",
    "# print the remaing number of features\n",
    "remaining_features_count = len(filtered_survey_data)\n",
    "print(\"Number of remaining features:\", remaining_features_count)\n",
    "\n",
    "survey_features_filtered = list(filtered_survey_data.index)\n",
    "print(survey_features_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique CMRC_id number: 7986\n"
     ]
    }
   ],
   "source": [
    "# Filter for invalid patients\n",
    "# count the unique CMRC_id\n",
    "unique_CMRC_id_count = df6['CMRC_id'].nunique()\n",
    "print(\"unique CMRC_id number:\", unique_CMRC_id_count)\n",
    "\n",
    "# groupby patient via year_come, and count the patient number by year_come\n",
    "max_year_come_by_patient = df5.groupby(['CMRC_id'])['year_come'].max().reset_index()\n",
    "count_by_year_come = max_year_come_by_patient.groupby('year_come')['CMRC_id'].count().reset_index()\n",
    "\n",
    "# using groupby to filter the patient that in the same year_come having 2 or more patients\n",
    "patients_to_remove = df6.groupby(['CMRC_id', 'year_come']).filter(lambda x: len(x) >= 2)['CMRC_id'].unique()\n",
    "df6_filtered = df6[~df6['CMRC_id'].isin(patients_to_remove)]\n",
    "\n",
    "#apply sliding window\n",
    "df7 = utils.sliding_window_multi_label_data(df6_filtered, input_window_size=1, target_window_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select key columns for conventional machine learning models\n",
    "other_columns = [\"sex\", \"age\", \"waist_y\", \"Glucose_AC_y\", \"Triglyceride_y\", \"HDL_C_y\", \"AST_GOT\", \"ALT_GPT\", \\\n",
    "          \"gamgt\", \"Insulin\", \"T_Cholesterol\", \"LDL_C_direct\", \"VLDL_C\", \"Non_HDL_C\", \"T_CHOL_HDL_C\", \\\n",
    "          \"LDL_C_HDL_C\", \"HS_CRP\", \"Hb_A1c\", \"Uric_Acid\",\n",
    "           \"HOMA_IR\", \"Adiponectin\", \\\n",
    "           \"Leptin\", \"TotalVitaminD\", \\\n",
    "           \"BMI\", \"DM_determine\", \"w\", \"hyper\", \\\n",
    "           \"fg\", \"HDL\", \"trig\", \"sarcf\", \"ms2\", \\\n",
    "           \"HBV_\", \"HCV_\", \"MAFLD\", \"CKD\", \\\n",
    "           'HBsAg_x_num', 'Anti_HCV_x_num', \\\n",
    "           'MAFLD_0', 'MAFLD_Obesity', 'MAFLD_MD', 'MAFLD_Diabetes', \\\n",
    "           'year_come']\n",
    "columns = other_columns + survey_features_filtered\n",
    "prefixes = [\"t1_\"]\n",
    "renamed_columns = utils.add_prefix(columns, prefixes)\n",
    "\n",
    "df8 = df7[renamed_columns].copy()\n",
    "# df8['t2_MAFLD_0'] = df7['t2_MAFLD_0']\n",
    "# df8['t2_MAFLD_Obesity'] = df7['t2_MAFLD_Obesity']\n",
    "# df8['t2_MAFLD_MD'] = df7['t2_MAFLD_MD']\n",
    "# df8['t2_MAFLD_Diabetes'] = df7['t2_MAFLD_Diabetes']\n",
    "# df8['t1_CMRC_id'] = df7['t1_CMRC_id']\n",
    "df8.loc[:, 't2_MAFLD_0'] = df7['t2_MAFLD_0']\n",
    "df8.loc[:, 't2_MAFLD_Obesity'] = df7['t2_MAFLD_Obesity']\n",
    "df8.loc[:, 't2_MAFLD_MD'] = df7['t2_MAFLD_MD']\n",
    "df8.loc[:, 't2_MAFLD_Diabetes'] = df7['t2_MAFLD_Diabetes']\n",
    "df8.loc[:, 't1_CMRC_id'] = df7['t1_CMRC_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1_sex</th>\n",
       "      <th>t1_age</th>\n",
       "      <th>t1_waist_y</th>\n",
       "      <th>t1_Glucose_AC_y</th>\n",
       "      <th>t1_Triglyceride_y</th>\n",
       "      <th>t1_HDL_C_y</th>\n",
       "      <th>t1_AST_GOT</th>\n",
       "      <th>t1_ALT_GPT</th>\n",
       "      <th>t1_gamgt</th>\n",
       "      <th>t1_Insulin</th>\n",
       "      <th>...</th>\n",
       "      <th>t1_RAND36_EF</th>\n",
       "      <th>t1_RAND36_GH</th>\n",
       "      <th>t1_RAND36_RP</th>\n",
       "      <th>t1_RAND36_RE</th>\n",
       "      <th>t2_MAFLD_0</th>\n",
       "      <th>t2_MAFLD_Obesity</th>\n",
       "      <th>t2_MAFLD_MD</th>\n",
       "      <th>t2_MAFLD_Diabetes</th>\n",
       "      <th>t1_CMRC_id</th>\n",
       "      <th>null_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>85.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>60.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.56</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A02013O51207P5052</td>\n",
       "      <td>0.042254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A02014I70719D9059</td>\n",
       "      <td>0.028169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>71.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>71.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.47</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A02014P40118F7096</td>\n",
       "      <td>0.098592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>91.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>51.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.55</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A02014V30517K5009</td>\n",
       "      <td>0.042254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>88.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A02014Z40719Z0013</td>\n",
       "      <td>0.014085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  t1_sex t1_age t1_waist_y t1_Glucose_AC_y t1_Triglyceride_y t1_HDL_C_y  \\\n",
       "0      0     62       85.0           103.0             192.0       60.7   \n",
       "1      0     62       64.0            90.0              72.0       80.0   \n",
       "2      0     35       71.0            89.0              54.0       71.3   \n",
       "3      1     74       91.0            87.0             122.0       51.2   \n",
       "4      0     61       88.0           107.0             207.0       43.0   \n",
       "\n",
       "  t1_AST_GOT t1_ALT_GPT t1_gamgt t1_Insulin  ... t1_RAND36_EF t1_RAND36_GH  \\\n",
       "0       18.0       22.0     17.0       4.56  ...          1.0          1.0   \n",
       "1       22.0       17.0      9.0        3.9  ...          3.0          4.0   \n",
       "2       38.0       33.0     52.0       5.47  ...          1.0          3.0   \n",
       "3       20.0       16.0     17.0      11.55  ...          4.0          4.0   \n",
       "4       21.0       33.0     18.0       10.2  ...          4.0          4.0   \n",
       "\n",
       "  t1_RAND36_RP t1_RAND36_RE t2_MAFLD_0 t2_MAFLD_Obesity t2_MAFLD_MD  \\\n",
       "0          0.0          1.0          1                0           0   \n",
       "1          4.0          4.0          1                0           0   \n",
       "2          4.0          4.0          1                0           0   \n",
       "3          4.0          4.0          1                0           0   \n",
       "4          4.0          4.0          1                0           0   \n",
       "\n",
       "  t2_MAFLD_Diabetes         t1_CMRC_id null_ratio  \n",
       "0                 0  A02013O51207P5052   0.042254  \n",
       "1                 0  A02014I70719D9059   0.028169  \n",
       "2                 0  A02014P40118F7096   0.098592  \n",
       "3                 0  A02014V30517K5009   0.042254  \n",
       "4                 0  A02014Z40719Z0013   0.014085  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df1 = df8[(df8['t1_MAFLD_0'] == 1) & (df8['t2_MAFLD_0'] != -1)]\n",
    "unique_records = filtered_df1.groupby('t1_CMRC_id').apply(utils.select_record).reset_index(drop=True)\n",
    "unique_records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop these cols\n",
    "cols_to_drop_only_MAFLD = ['t1_MAFLD', 't1_MAFLD_0',\\\n",
    "                           't1_MAFLD_Obesity', 't1_MAFLD_MD', 't1_MAFLD_Diabetes', \\\n",
    "                           't1_CMRC_id', 'null_ratio'\\\n",
    "                           ]\n",
    "\n",
    "df9_processed = unique_records.drop(cols_to_drop_only_MAFLD, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_combined shape:  (4408, 130)\n",
      "y shape:  (4408, 4)\n"
     ]
    }
   ],
   "source": [
    "# start modeling preparation - one-hot encoding \n",
    "# split categorical and numerical variables\n",
    "\n",
    "features = df9_processed.columns.drop(['t2_MAFLD_0', 't2_MAFLD_Obesity', 't2_MAFLD_Diabetes', 't2_MAFLD_MD'])\n",
    "other_categorical_features = ['t1_sex', 't1_w', 't1_DM_determine', 't1_CKD']\n",
    "prefixes = [\"t1_\"]\n",
    "\n",
    "# all survey features are categorical vars\n",
    "survey_categorical_features = utils.add_prefix(survey_features_filtered, prefixes)\n",
    "categorical_features = other_categorical_features + survey_categorical_features\n",
    "\n",
    "# Continous Var: Scaling and Missing value handling\n",
    "numeric_features = df9_processed.columns.drop(categorical_features).drop(['t2_MAFLD_0', 't2_MAFLD_Obesity', 't2_MAFLD_Diabetes', 't2_MAFLD_MD'])\n",
    "X_numeric = df9_processed[numeric_features]\n",
    "scaler = StandardScaler()\n",
    "X_numeric_scaled = scaler.fit_transform(X_numeric)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_numeric_scaled_imputed = imputer.fit_transform(X_numeric_scaled)\n",
    "\n",
    "# Discrete Var: one-hot encoding\n",
    "# One hot for categorical var - nan with 0 - use for contrastive learning\n",
    "X_categorical = df9_processed[categorical_features]\n",
    "X_categorical_str = X_categorical.astype(str)\n",
    "X_categorical_encoded = pd.get_dummies(X_categorical_str)\n",
    "\n",
    "nan_columns = [col for col in X_categorical_encoded.columns if 'nan' in col]\n",
    "# Remove 'nan' columns from the dataframe\n",
    "X_categorical_encoded.drop(columns=nan_columns, inplace=True)\n",
    "\n",
    "# process target variable\n",
    "y = df9_processed[['t2_MAFLD_0', 't2_MAFLD_Obesity', 't2_MAFLD_Diabetes', 't2_MAFLD_MD']]\n",
    "y = y.astype(int)\n",
    "\n",
    "# concat\n",
    "X_numeric_scaled_imputed = pd.DataFrame(X_numeric_scaled_imputed, columns=X_numeric.columns)\n",
    "X_numeric_scaled_imputed.reset_index(drop=True, inplace=True)\n",
    "X_categorical_encoded.reset_index(drop=True, inplace=True)\n",
    "X_combined = pd.concat([X_numeric_scaled_imputed, X_categorical_encoded], axis=1)\n",
    "\n",
    "print('X_combined shape: ',X_combined.shape)\n",
    "print('y shape: ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique classes in y_train_lp: 5\n",
      "t2_MAFLD_0                            3667\n",
      "t2_MAFLD_Obesity                       537\n",
      "t2_MAFLD_Obesity,t2_MAFLD_Diabetes     157\n",
      "t2_MAFLD_MD                             34\n",
      "t2_MAFLD_Diabetes,t2_MAFLD_MD           13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#   Change y to 1-d array to fit the multiclass probelm\n",
    "# y_feture_list = y.columns.tolist()\n",
    "# # y[y_feture_list].value_counts(dropna = False)\n",
    "# for column in y.columns:\n",
    "#     print(f\"Value counts for {column}:\")\n",
    "#     print(y[column].value_counts(dropna=False))\n",
    "#     print(\"\\n\")\n",
    "\n",
    "y_lp = y.apply(lambda row: ','.join(row.index[row == 1]), axis=1)\n",
    "print(\"Number of unique classes in y_train_lp:\", y_lp.nunique())\n",
    "print(y_lp.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = utils.process_label_powerset(y, y_lp)\n",
    "y_new.head(3)\n",
    "\n",
    "# Check index for X_Combined and y_new\n",
    "assert(X_combined.index.equals(y_new.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data points belong to exactly one class: True\n"
     ]
    }
   ],
   "source": [
    "# Check for multiclass problem\n",
    "row_sums = y_new.sum(axis=1)\n",
    "all_single_label = (row_sums == 1).all()\n",
    "\n",
    "print(f\"All data points belong to exactly one class: {all_single_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to 1d array\n",
    "y_new = y_new.reset_index(drop=True)\n",
    "\n",
    "y_new_1d = y_new.idxmax(axis=1)\n",
    "class_mapping = {label: idx for idx, label in enumerate(y_new.columns)}\n",
    "y_new_1d = y_new_1d.map(class_mapping).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3667\n",
       "2     537\n",
       "3     157\n",
       "1      34\n",
       "4      13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new_1d.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check index for X_Combined and y_new_1d\n",
    "assert(X_combined.index.equals(y_new_1d.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train: (2820, 130)\n",
      "Size of y_train: (2820,)\n",
      "Size of X_val: (706, 130)\n",
      "Size of y_val: (706,)\n",
      "Size of X_test: (882, 130)\n",
      "Size of y_test: (882,)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_new_1d, test_size=0.2, random_state=42, stratify=y_new_1d)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "# get the size for each training and validation\n",
    "print(\"Size of X_train:\", X_train.shape)\n",
    "print(\"Size of y_train:\", y_train.shape)\n",
    "print(\"Size of X_val:\", X_val.shape)\n",
    "print(\"Size of y_val:\", y_val.shape)\n",
    "print(\"Size of X_test:\", X_test.shape)\n",
    "print(\"Size of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train val test dataset for next usage\n",
    "import os\n",
    "# use for constrastive learning, benchmark etc\n",
    "DATA_DIR = \"../Data/train_test_data/\"\n",
    "\n",
    "feature_columns = X_train.columns.tolist()\n",
    "train_df = pd.DataFrame(data=X_train, columns=feature_columns)\n",
    "train_df[\"target\"] = y_train\n",
    "train_df.to_csv(os.path.join(DATA_DIR, \"train.csv\"), index=False)\n",
    "\n",
    "val_df = pd.DataFrame(data=X_val, columns=feature_columns)\n",
    "val_df[\"target\"] = y_val\n",
    "val_df.to_csv(os.path.join(DATA_DIR, \"val.csv\"), index=False)\n",
    "\n",
    "test_df = pd.DataFrame(data=X_test, columns=feature_columns)\n",
    "test_df[\"target\"] = y_test\n",
    "test_df.to_csv(os.path.join(DATA_DIR, \"test.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
